{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c6c2371",
   "metadata": {},
   "source": [
    "# Installer les librairies n√©cessaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7898654c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ pandas est d√©j√† install√©.\n",
      "‚úÖ numpy est d√©j√† install√©.\n",
      "‚úÖ streamlit est d√©j√† install√©.\n",
      "‚úÖ ta est d√©j√† install√©.\n",
      "‚úÖ matplotlib est d√©j√† install√©.\n",
      "üì¶ Installation de scikit-learn...\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikit-learn in /Users/enzoberreur/Library/Python/3.9/lib/python/site-packages (1.6.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /Users/enzoberreur/Library/Python/3.9/lib/python/site-packages (from scikit-learn) (1.26.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Users/enzoberreur/Library/Python/3.9/lib/python/site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/enzoberreur/Library/Python/3.9/lib/python/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/enzoberreur/Library/Python/3.9/lib/python/site-packages (from scikit-learn) (3.6.0)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "required_libs = [\n",
    "    \"pandas\",\n",
    "    \"numpy\",\n",
    "    \"streamlit\",\n",
    "    \"ta\",\n",
    "    \"matplotlib\",\n",
    "    \"scikit-learn\"\n",
    "]\n",
    "\n",
    "for lib in required_libs:\n",
    "    try:\n",
    "        __import__(lib)\n",
    "        print(f\"‚úÖ {lib} est d√©j√† install√©.\")\n",
    "    except ImportError:\n",
    "        print(f\"üì¶ Installation de {lib}...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", lib])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d241493",
   "metadata": {},
   "source": [
    "# Lancer pour importer les donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3107ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÅ Mise √† jour : BTCUSDT_1h.csv\n",
      "‚úÖ Aucune nouvelle donn√©e.\n",
      "üîÅ Mise √† jour : BTCUSDT_4h.csv\n",
      "‚úÖ Aucune nouvelle donn√©e.\n",
      "üîÅ Mise √† jour : BTCUSDT_1d.csv\n",
      "‚úÖ Aucune nouvelle donn√©e.\n",
      "üîÅ Mise √† jour : ETHUSDT_1h.csv\n",
      "‚úÖ Aucune nouvelle donn√©e.\n",
      "üîÅ Mise √† jour : ETHUSDT_4h.csv\n",
      "‚úÖ Aucune nouvelle donn√©e.\n",
      "üîÅ Mise √† jour : ETHUSDT_1d.csv\n",
      "‚úÖ Aucune nouvelle donn√©e.\n",
      "üîÅ Mise √† jour : BNBUSDT_1h.csv\n",
      "‚úÖ Aucune nouvelle donn√©e.\n",
      "üîÅ Mise √† jour : BNBUSDT_4h.csv\n",
      "‚úÖ Aucune nouvelle donn√©e.\n",
      "üîÅ Mise √† jour : BNBUSDT_1d.csv\n",
      "‚úÖ Aucune nouvelle donn√©e.\n",
      "üîÅ Mise √† jour : SOLUSDT_1h.csv\n",
      "‚úÖ Aucune nouvelle donn√©e.\n",
      "üîÅ Mise √† jour : SOLUSDT_4h.csv\n",
      "‚úÖ Aucune nouvelle donn√©e.\n",
      "üîÅ Mise √† jour : SOLUSDT_1d.csv\n",
      "‚úÖ Aucune nouvelle donn√©e.\n",
      "üîÅ Mise √† jour : DOGEUSDT_1h.csv\n",
      "‚úÖ Aucune nouvelle donn√©e.\n",
      "üîÅ Mise √† jour : DOGEUSDT_4h.csv\n",
      "‚úÖ Aucune nouvelle donn√©e.\n",
      "üîÅ Mise √† jour : DOGEUSDT_1d.csv\n",
      "‚úÖ Aucune nouvelle donn√©e.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from binance.client import Client\n",
    "\n",
    "# Connexion √† l'API Binance \n",
    "client = Client()\n",
    "\n",
    "# R√©pertoire pour les fichiers CSV\n",
    "save_dir = \"Historique\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# Paires et timeframes √† g√©rer\n",
    "pairs = [\"BTCUSDT\", \"ETHUSDT\", \"BNBUSDT\", \"SOLUSDT\", \"DOGEUSDT\"]\n",
    "timeframes = {\n",
    "    \"1h\": Client.KLINE_INTERVAL_1HOUR,\n",
    "    \"4h\": Client.KLINE_INTERVAL_4HOUR,\n",
    "    \"1d\": Client.KLINE_INTERVAL_1DAY\n",
    "}\n",
    "start_date_str = \"1 Jan, 2017\"\n",
    "\n",
    "# Fonction pour t√©l√©charger tout l'historique d'une paire / interval\n",
    "def get_full_history(symbol, interval, start_str):\n",
    "    print(f\"‚¨áÔ∏è T√©l√©chargement : {symbol} - {interval}\")\n",
    "    all_data = []\n",
    "    start_time = int(datetime.strptime(start_str, \"%d %b, %Y\").timestamp() * 1000)\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            data = client.get_klines(\n",
    "                symbol=symbol,\n",
    "                interval=interval,\n",
    "                startTime=start_time,\n",
    "                limit=1000\n",
    "            )\n",
    "            if not data:\n",
    "                break\n",
    "\n",
    "            df = pd.DataFrame(data, columns=[\n",
    "                \"open_time\", \"open\", \"high\", \"low\", \"close\", \"volume\",\n",
    "                \"close_time\", \"quote_asset_volume\", \"number_of_trades\",\n",
    "                \"taker_buy_base_asset_volume\", \"taker_buy_quote_asset_volume\", \"ignore\"\n",
    "            ])\n",
    "            df[\"open_time\"] = pd.to_datetime(df[\"open_time\"], unit='ms')\n",
    "            df[\"close_time\"] = pd.to_datetime(df[\"close_time\"], unit='ms')\n",
    "\n",
    "            all_data.append(df)\n",
    "\n",
    "            start_time = int(data[-1][6]) + 1  # close_time + 1ms\n",
    "            time.sleep(1)\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Erreur : {e}\")\n",
    "            break\n",
    "\n",
    "    return pd.concat(all_data) if all_data else pd.DataFrame()\n",
    "\n",
    "# Fonction de mise √† jour d'un fichier CSV\n",
    "def update_history(symbol, interval_key):\n",
    "    interval = timeframes[interval_key]\n",
    "    filename = f\"{symbol}_{interval_key}.csv\"\n",
    "    filepath = os.path.join(save_dir, filename)\n",
    "\n",
    "    if os.path.exists(filepath):\n",
    "        print(f\"üîÅ Mise √† jour : {filename}\")\n",
    "        df_existing = pd.read_csv(filepath)\n",
    "        df_existing[\"close_time\"] = pd.to_datetime(df_existing[\"close_time\"])\n",
    "\n",
    "        last_timestamp = int(df_existing[\"close_time\"].max().timestamp() * 1000) + 1\n",
    "        new_data = []\n",
    "\n",
    "        while True:\n",
    "            try:\n",
    "                data = client.get_klines(\n",
    "                    symbol=symbol,\n",
    "                    interval=interval,\n",
    "                    startTime=last_timestamp,\n",
    "                    limit=1000\n",
    "                )\n",
    "                if not data:\n",
    "                    break\n",
    "\n",
    "                df = pd.DataFrame(data, columns=[\n",
    "                    \"open_time\", \"open\", \"high\", \"low\", \"close\", \"volume\",\n",
    "                    \"close_time\", \"quote_asset_volume\", \"number_of_trades\",\n",
    "                    \"taker_buy_base_asset_volume\", \"taker_buy_quote_asset_volume\", \"ignore\"\n",
    "                ])\n",
    "                df[\"open_time\"] = pd.to_datetime(df[\"open_time\"], unit='ms')\n",
    "                df[\"close_time\"] = pd.to_datetime(df[\"close_time\"], unit='ms')\n",
    "\n",
    "                new_data.append(df)\n",
    "\n",
    "                last_timestamp = int(data[-1][6]) + 1\n",
    "                time.sleep(1)\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Erreur MAJ : {e}\")\n",
    "                break\n",
    "\n",
    "        if new_data:\n",
    "            df_new = pd.concat(new_data)\n",
    "            df_combined = pd.concat([df_existing, df_new])\n",
    "            df_combined.drop_duplicates(subset=\"close_time\", inplace=True)\n",
    "            df_combined.to_csv(filepath, index=False)\n",
    "            print(f\"‚úÖ Fichier mis √† jour : {filename} ({len(df_combined)} lignes)\")\n",
    "        else:\n",
    "            print(\"‚úÖ Aucune nouvelle donn√©e.\")\n",
    "    else:\n",
    "        print(f\"üìÅ Cr√©ation : {filename}\")\n",
    "        df = get_full_history(symbol, interval, start_date_str)\n",
    "        if not df.empty:\n",
    "            df.to_csv(filepath, index=False)\n",
    "            print(f\"‚úÖ Fichier cr√©√© : {filename} ({len(df)} lignes)\")\n",
    "        else:\n",
    "            print(\"‚ùå Aucune donn√©e trouv√©e.\")\n",
    "\n",
    "# Lancer le script pour toutes les paires et timeframes\n",
    "for pair in pairs:\n",
    "    for tf in timeframes.keys():\n",
    "        update_history(pair, tf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a4ccd2",
   "metadata": {},
   "source": [
    "# V√©rifier que tout les fichiers sont √† jour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4b7fd71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Tous les fichiers n√©cessaires sont pr√©sents dans 'Backend'.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "required_files = [\n",
    "    \"Backend/app.py\",\n",
    "    \"Backend/backtester.py\",\n",
    "    \"Backend/metrics.py\",\n",
    "    \"Backend/models.py\",\n",
    "    \"Backend/optimizer.py\",\n",
    "    \"Backend/strategies.py\"\n",
    "]\n",
    "\n",
    "missing = [f for f in required_files if not os.path.exists(f)]\n",
    "\n",
    "if missing:\n",
    "    print(f\"‚ö†Ô∏è Fichiers manquants dans 'Backend' : {missing}\")\n",
    "else:\n",
    "    print(\"‚úÖ Tous les fichiers n√©cessaires sont pr√©sents dans 'Backend'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61fa83d",
   "metadata": {},
   "source": [
    "# D√©marrer l'application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b6fcd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\n",
      "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
      "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://10.40.1.186:8501\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m\u001b[1m  For better performance, install the Watchdog module:\u001b[0m\n",
      "\n",
      "  $ xcode-select --install\n",
      "  $ pip install watchdog\n",
      "            \u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!streamlit run backend/app.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
